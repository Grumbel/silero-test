#!/usr/bin/env python3


from typing import List

import argparse
import os
import queue
import simpleaudio
import sys
import torch
from threading import Thread
from xdg.BaseDirectory import xdg_cache_home


LANGUAGE_MODEL_URLS = {
    'en':  "https://models.silero.ai/models/tts/en/v3_en.pt",
    'de': "https://models.silero.ai/models/tts/de/v3_de.pt",
    'pt': "https://models.silero.ai/models/tts/es/v3_es.pt",
    'fr': "https://models.silero.ai/models/tts/fr/v3_fr.pt",
    'ua': "https://models.silero.ai/models/tts/ua/v3_ua.pt",
    'uz': "https://models.silero.ai/models/tts/uz/v3_uz.pt",
    'xal': "https://models.silero.ai/models/tts/xal/v3_xal.pt",
    'indic': "https://models.silero.ai/models/tts/indic/v3_indic.pt",
}


NLTK_DATA_PUNKT_DIR = "NLTK_DATA_PUNKT_PLACEHOLDER"


class Player:

    def __init__(self) -> None:
        self.queue = queue.Queue()
        self.wave_obj = None
        self.play_obj = None
        self.thread = Thread(target=lambda: self.run())
        self.thread.start()

    def add(self, filename: str) -> None:
        print(f"Player.add: {filename}")
        self.queue.put(filename)

    def quit(self) -> None:
        print(f"Player.quit")
        self.queue.put(None)
        self.thread.join()

    def run(self):
        print("Player started")
        while True:
            wave_file = self.queue.get()
            if wave_file is None:
                break
            self.wave_obj = simpleaudio.WaveObject.from_wave_file(wave_file)
            self.play_obj = self.wave_obj.play()
            self.play_obj.wait_done()


def split_sentences(text: str) -> List[str]:
    NLTK_DATA_PUNKT_DIR = "NLTK_DATA_PUNKT_DIR_PLACEHOLDER"
    if os.path.isdir(NLTK_DATA_PUNKT_DIR):
        import nltk
        tokenize = nltk.data.load(os.path.join(NLTK_DATA_PUNKT_DIR, 'PY3/english.pickle'))
        return tokenize.sentences_from_text(text)
    else:
        print("warning: NLTK_DATA_PUNKT_DIR not set, treating text as one sentence", file=sys.stderr)
        return [text]


def parse_args(args: List[str]) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Text to Speech")
    group_ex = parser.add_mutually_exclusive_group()
    group_ex.add_argument("-t", "--text", metavar="TETX", type=str, default=None,
                        help="Convert TEXT to wav")
    group_ex.add_argument("-f", "--file", metavar="FILE", type=str, default=None,
                          help="Convert content of FILE to wav")
    parser.add_argument("-m", "--model", metavar="FILE", type=str, default=None,
                        help="Model file to use ")
    parser.add_argument("-l", "--lang", metavar="LANGUAGE", type=str, default='en',
                        help="Use language LANGUAGE")
    parser.add_argument("-s", "--speaker", metavar="SPEAKER", type=str, default=None,
                        help="Speaker to use")
    parser.add_argument("-r", "--rate", metavar="RATE", type=int, default=48000,
                        help="Sample rate")
    parser.add_argument("-p", "--play", action='store_true', default=False,
                        help="Play the generated wav")
    parser.add_argument("-o", "--output", metavar="FILE", type=str, default=None,
                        help="Write wave to FILE")
    return parser.parse_args(args)


def main(argv: List[str]) -> None:
    opts = parse_args(argv[1:])

    cache_dir = os.path.join(xdg_cache_home, "silero-test")
    if not os.path.isdir(cache_dir):
        os.makedirs(os.path.join(cache_dir))

    if opts.output is None:
        raise RuntimeError("--output PATH required")

    model_file: str
    if opts.model is not None:
        model_file = opts.model
    else:
        model_url = LANGUAGE_MODEL_URLS[opts.lang]
        model_file = os.path.join(cache_dir, f"{opts.lang}.pt")
        if not os.path.isfile(model_file):
            print(f"Downloading {model_url} to {model_file}")
            torch.hub.download_url_to_file(model_url, dst=model_file, progress=True)

    device = torch.device('cpu')
    torch.set_num_threads(torch.multiprocessing.cpu_count())

    model = torch.package.PackageImporter(model_file).load_pickle("tts_models", "model")
    model.to(device)

    print(f"Model: {model_file}")
    print(f"Speakers: {' '.join(model.speakers)}")
    print(f"Languages: {' '.join(LANGUAGE_MODEL_URLS.keys())}")

    if opts.speaker is None:
        speaker = model.speakers[0]
    else:
        speaker = opts.speaker

    if opts.file:
        with open(opts.file) as fin:
            text = fin.read()
    else:
        text = opts.text

    if text is None:
        raise RuntimeError("no text given")

    outfile_root, outfile_ext = os.path.splitext(opts.output)
    sentences = split_sentences(text)

    if opts.play:
        player = Player()
    else:
        player = None

    for idx, sentence in enumerate(sentences):
        outfile = f"{outfile_root}-{idx:06d}{outfile_ext}"
        print(f"Processing {outfile}: {sentence!r}")
        try:
            audio_path = model.save_wav(audio_path=outfile,
                                        text=sentence,
                                        speaker=speaker,
                                        sample_rate=opts.rate)
            if player is not None:
                player.add(audio_path)

            print(f"Written: {audio_path}")
        except Exception as err:
            # ValueError() is thrown when the sentence only contains numbers
            print(f"error: failed to process {sentence!r}: {err!r}")

    if opts.play:
        player.quit()


if __name__ == "__main__":
    main(sys.argv)


# EOF #
